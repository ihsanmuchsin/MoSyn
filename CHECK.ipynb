{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_file = \"/media/ihsan/DATA/THESIS/MISC/TEMP/ADHORE/Drosophila/synteny.json\"\n",
    "with open(json_file, 'r') as f:\n",
    "    json_dict = json.load(f)\n",
    "    \n",
    "print (len(json_dict[\"1\"][\"segments\"][\"1\"][\"elements\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yaml_file = \"/media/ihsan/DATA/THESIS/MISC/TEMP/ADHORE/Drosophila/synteny.yaml\"\n",
    "with open(yaml_file, 'r') as f:\n",
    "    yaml_dict = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (len(yaml_dict[1][\"segments\"][1][\"elements\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = \"/media/ihsan/DATA/THESIS/MISC/TEMP/ADHORE/Drosophila/synteny.pickle\"\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    pickle_dict = pickle.load(f)\n",
    "    \n",
    "print (len(pickle_dict[1][\"segments\"][1][\"elements\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_species = ['Caenorhabditis', 'Drosophila', 'Trichinella']\n",
    "all_alignment = ['BLAST', 'DIAMOND']\n",
    "for species in all_species:\n",
    "    for alignment in all_alignment:\n",
    "        the_folder = '/media/ihsan/DATA/THESIS/RUN/PREP/'+species+'/iadhore/family/'+alignment\n",
    "        os.makedirs(the_folder)\n",
    "        print(the_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_species = ['Caenorhabditis', 'Drosophila', 'Trichinella']\n",
    "all_alignment = ['BLAST', 'DIAMOND']\n",
    "for species in all_species:\n",
    "    for alignment in all_alignment:\n",
    "        the_folder = '/media/ihsan/DATA/THESIS/RUN/PREP/'+species+'/orthofinder/Orthogroups_gene/'+alignment+'/Orthogroups.txt'\n",
    "        print(the_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_species = ['Caenorhabditis', 'Drosophila', 'Trichinella']\n",
    "all_alignment = ['BLAST', 'DIAMOND']\n",
    "for species in all_species:\n",
    "    for alignment in all_alignment:\n",
    "        the_folder = '/media/ihsan/DATA/THESIS/RUN/PREP/'+species+'/iadhore/family/'+alignment+'/iadhore_family.tsv'\n",
    "        print(the_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_species = ['Caenorhabditis', 'Drosophila', 'Trichinella']\n",
    "all_alignment = ['BLAST', 'DIAMOND']\n",
    "program = 'python'\n",
    "command = '/media/ihsan/DATA/THESIS/PIPELINE/ms-prep.py'\n",
    "subcommand = 'og2fam'\n",
    "\n",
    "for species in all_species:\n",
    "    for alignment in all_alignment:\n",
    "        infile = '/media/ihsan/DATA/THESIS/RUN/PREP/'+species+'/orthofinder/Orthogroups_gene/'+alignment+'/Orthogroups.txt'\n",
    "        outfile = '/media/ihsan/DATA/THESIS/RUN/PREP/'+species+'/iadhore/family/'+alignment+'/iadhore_family.tsv'\n",
    "        subprocess.call([program, command, subcommand, '--input', infile, '--output', outfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_species = ['Caenorhabditis', 'Drosophila', 'Trichinella']\n",
    "all_alignment = ['BLAST', 'DIAMOND']\n",
    "for species in all_species:\n",
    "    for alignment in all_alignment:\n",
    "        the_folder = '/media/ihsan/DATA/THESIS/RUN/PREP/'+species+'/iadhore/config/'+alignment\n",
    "        os.makedirs(the_folder)\n",
    "        print(the_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_int(int_string):\n",
    "    \"\"\"\n",
    "    Check if the string can be converted to int. Return int if TRUE\n",
    "    :param int_string: String\n",
    "    :return: Integer or String\n",
    "    \"\"\"\n",
    "    try:\n",
    "        int_string = int(int_string)\n",
    "    except ValueError:\n",
    "        return int_string\n",
    "    return int_string\n",
    "\n",
    "check_int = ['12', '12.2', 'test', '+', '-']\n",
    "for c in check_int:\n",
    "    print(type(is_int(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = set([1, 2, 3])\n",
    "s2 = set([1, 2, 3])\n",
    "sfin = s1 & s2\n",
    "print(sfin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# smaller problem of alignment\n",
    "distance_dictionary = {\"dmel\": [25, 55, 75, 76, 100, 120],\n",
    "                      \"dsim\": [24, 54, 76, 77, 101, 200, 210, 215, 220],\n",
    "                      \"dyak\": [1, 57, 56, 74, 99, 170, 189, 195]}\n",
    "\n",
    "minimum_key = None\n",
    "minimum_elem = None\n",
    "\n",
    "for k, v in distance_dictionary.items():\n",
    "    \n",
    "    this_len = len(v)\n",
    "    \n",
    "    if not minimum_elem:\n",
    "        minimum_elem = this_len\n",
    "        minimum_key = k\n",
    "        continue\n",
    "    \n",
    "    if this_len < minimum_elem:\n",
    "        minimum_key = k\n",
    "        \n",
    "other_keys = set(distance_dictionary.keys())\n",
    "other_keys.discard(minimum_key)\n",
    "\n",
    "window = 2\n",
    "\n",
    "all_pairs = []\n",
    "for dist in distance_dictionary[minimum_key]:\n",
    "    pairs = None\n",
    "    for key in other_keys:\n",
    "        selected_pair = None\n",
    "        min_diff = None\n",
    "        for d in distance_dictionary[key]:\n",
    "            diff = abs(dist-d)\n",
    "            if diff <= window:\n",
    "                if not min_diff:\n",
    "                    selected_pair = d\n",
    "                    min_diff = diff\n",
    "                    continue\n",
    "                if diff < min_diff:\n",
    "                    selected_pair = d\n",
    "                    min_diff = diff\n",
    "        \n",
    "        if not selected_pair:\n",
    "            break\n",
    "            \n",
    "        if not pairs:\n",
    "            pairs = []\n",
    "        \n",
    "        pairs.append(selected_pair)\n",
    "    \n",
    "    if not pairs:\n",
    "        continue\n",
    "    \n",
    "    pairs.append(dist)\n",
    "    if len(pairs)==len(distance_dictionary):\n",
    "        all_pairs.append(pairs)\n",
    "print(all_pairs)       \n",
    "\n",
    "new_all_pairs = []\n",
    "prev_el = None\n",
    "prev_std = None\n",
    "\n",
    "for el in all_pairs:\n",
    "    \n",
    "    this_std = numpy.std(el)\n",
    "    \n",
    "    if not prev_el:\n",
    "        prev_el = el\n",
    "        prev_std = this_std\n",
    "        new_all_pairs.append(el)\n",
    "        continue\n",
    "    \n",
    "    check_prev = True\n",
    "    for e in el:\n",
    "        if e in prev_el:\n",
    "            if this_std < prev_std:\n",
    "                new_all_pairs.remove(prev_el)\n",
    "                break\n",
    "            \n",
    "            check_prev = False\n",
    "            break\n",
    "    \n",
    "    if check_prev:\n",
    "        prev_el = el\n",
    "        prev_std = this_std\n",
    "        new_all_pairs.append(el)\n",
    "                \n",
    "print(new_all_pairs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.std([76, 74, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/media/ihsan/DATA/THESIS/RUN/CORE/STORM/Drosophila/17/holohan_exp/Drosophila_melanogaster.storm', 'r') as handle:\n",
    "    record = motifs.parse(handle, 'TRANSFAC')\n",
    "    for r in record:\n",
    "        print (r.counts)\n",
    "        for k, v in r.items():\n",
    "            print (k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iadhore_dict = pi.iadhore_result_folder_to_dict(\"/media/ihsan/DATA/THESIS/MISC/TEMP/ADHORE/Drosophila/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iadhore_dict = pi.get_complete_synteny_dict(iadhore_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iadhore_dict_with_locations = cm.add_location_to_iadhore_synteny(iadhore_dict, \"/media/ihsan/DATA/THESIS/MATERIAL/Drosophila/GTF/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import prep.iadhore as pi\n",
    "import core.mosyn as cm\n",
    "import prep.gtf as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('iadhore_plus_location.yaml', 'r') as stream:\n",
    "    iadhore_dict_with_locations = yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iadhore_dict_with_motifs = cm.add_motifs_into_synteny(iadhore_dict_with_locations, \"/media/ihsan/DATA/THESIS/RUN/PREP/Drosophila/storm/17/holohan_exp/GTF/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('iadhore_plus_motifs.yaml', 'w') as stream:\n",
    "    yaml.dump(iadhore_dict_with_motifs, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restructured_iadhore = cm.restructure_iadhore_dict_to_position(iadhore_dict_with_motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('iadhore_plus_motifs_restr.yaml', 'w') as stream:\n",
    "    yaml.dump(restructured_iadhore, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# smaller problem of alignment\n",
    "distance_dictionary = {\"dmel\": [25, 55, 75, 78, 100, 120, 248],\n",
    "                      \"dsim\": [24, 54, 76, 77, 101, 200, 210, 215, 220, 250],\n",
    "                      \"dyak\": [1, 57, 56, 74, 99, 170, 189, 195, 252]}\n",
    "\n",
    "window = 2\n",
    "\n",
    "all_pairs = []\n",
    "for k in distance_dictionary.keys():\n",
    "    \n",
    "    other_keys = set(distance_dictionary.keys())\n",
    "    other_keys.discard(k)\n",
    "    \n",
    "    for dist in distance_dictionary[k]:\n",
    "        \n",
    "        pairs = set()\n",
    "        \n",
    "        for key in other_keys:\n",
    "            selected_pair = None\n",
    "            min_diff = None\n",
    "            for d in distance_dictionary[key]:\n",
    "                diff = abs(dist-d)\n",
    "                if diff <= window:\n",
    "                    if min_diff == None:\n",
    "                        selected_pair = d\n",
    "                        min_diff = diff\n",
    "                        continue\n",
    "                    if diff < min_diff:\n",
    "                        selected_pair = d\n",
    "                        min_diff = diff\n",
    "\n",
    "            if not selected_pair:\n",
    "                continue\n",
    "\n",
    "            pairs.add(selected_pair)\n",
    "        \n",
    "        pairs.add(dist)\n",
    "        \n",
    "        if len(pairs)>1:\n",
    "            if pairs not in all_pairs:\n",
    "                all_pairs.append(pairs)\n",
    "\n",
    "print(all_pairs)\n",
    "\n",
    "new_all_pairs = []\n",
    "\n",
    "for el in all_pairs:\n",
    "    \n",
    "    if not new_all_pairs:\n",
    "        new_all_pairs.append(el)\n",
    "        continue\n",
    "    \n",
    "    check_prev = True\n",
    "    for e in el:\n",
    "        for ef in new_all_pairs:\n",
    "            if e in ef:\n",
    "                \n",
    "                if len(el) > len(ef):\n",
    "                    new_all_pairs.remove(ef)\n",
    "                    continue\n",
    "                \n",
    "                if len(el) < len(ef):\n",
    "                    check_prev = False\n",
    "                    break\n",
    "                    \n",
    "                this_std = np.std(list(el))\n",
    "                that_std = np.std(list(ef))\n",
    "                \n",
    "                if this_std < that_std:\n",
    "                    new_all_pairs.remove(ef)\n",
    "                    continue\n",
    "                    \n",
    "                check_prev = False\n",
    "                break\n",
    "                \n",
    "        if not check_prev:\n",
    "            break\n",
    "    \n",
    "    if check_prev:\n",
    "        new_all_pairs.append(el)\n",
    "                \n",
    "print(new_all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "single = []\n",
    "for value in distance_dictionary.values():\n",
    "    for val in value:\n",
    "        check_single = True\n",
    "        for pair in new_all_pairs:  \n",
    "            if val in pair:\n",
    "                check_single = False\n",
    "                break\n",
    "        if check_single:\n",
    "            single.append(val)\n",
    "print(single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# smaller problem of alignment\n",
    "distance_dictionary = {\"dmel\": [25, 28, 75, 78, 100, 104, 248],\n",
    "                      \"dsim\": [29, 26, 76, 79, 101, 105, 210, 215, 220, 250],\n",
    "                      \"dyak\": [27, 30, 77, 80, 102, 106, 225, 245, 252]}\n",
    "\n",
    "window = 10\n",
    "\n",
    "everything_pairs = []\n",
    "for k in distance_dictionary.keys():\n",
    "    \n",
    "    other_keys = set(distance_dictionary.keys())\n",
    "    other_keys.discard(k)\n",
    "    \n",
    "    \n",
    "    for dist in distance_dictionary[k]:\n",
    "        all_pairs = []\n",
    "        for key in other_keys:\n",
    "            selected_pairs = []\n",
    "            for d in distance_dictionary[key]:\n",
    "                diff = abs(dist-d)\n",
    "                if diff <= window:\n",
    "                    selected_pairs.append(d)\n",
    "                    continue\n",
    "                    \n",
    "            if not selected_pairs:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            if not all_pairs:\n",
    "                for sl in selected_pairs:\n",
    "                    all_pairs.append([sl])\n",
    "                continue\n",
    "            \n",
    "            mod_all_pairs = []    \n",
    "            for pairs in all_pairs:\n",
    "                for sl in selected_pairs:\n",
    "                    mod_all_pairs.append(pairs + [sl])\n",
    "            all_pairs = mod_all_pairs\n",
    "        \n",
    "        if not all_pairs:\n",
    "            continue\n",
    "            \n",
    "        for pairs in all_pairs:\n",
    "            everything_pairs.append(pairs + [dist])\n",
    "\n",
    "print (everything_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_all_pairs = []\n",
    "\n",
    "for el in everything_pairs:\n",
    "    \n",
    "    if not new_all_pairs:\n",
    "        new_all_pairs.append(el)\n",
    "        continue\n",
    "    \n",
    "    check_prev = True\n",
    "    for e in el:\n",
    "        for ef in new_all_pairs:\n",
    "            if e in ef:\n",
    "                \n",
    "                if len(el) > len(ef):\n",
    "                    new_all_pairs.remove(ef)\n",
    "                    continue\n",
    "                \n",
    "                if len(el) < len(ef):\n",
    "                    check_prev = False\n",
    "                    break\n",
    "                    \n",
    "                this_std = sum(list(el))\n",
    "                that_std = sum(list(ef))\n",
    "                \n",
    "                if this_std < that_std:\n",
    "                    new_all_pairs.remove(ef)\n",
    "                    continue\n",
    "                    \n",
    "                check_prev = False\n",
    "                break\n",
    "                \n",
    "        if not check_prev:\n",
    "            break\n",
    "    \n",
    "    if check_prev:\n",
    "        new_all_pairs.append(el)\n",
    "        \n",
    "for el in everything_pairs:\n",
    "    \n",
    "    check_prev = True\n",
    "    for e in el:\n",
    "        for ef in new_all_pairs:\n",
    "            if e in ef:\n",
    "                check_prev = False\n",
    "                break\n",
    "                \n",
    "        if not check_prev:\n",
    "            break\n",
    "    \n",
    "    if check_prev:\n",
    "        new_all_pairs.append(el)\n",
    "                \n",
    "print(new_all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[[26, 27, 25], [29, 30, 28], [76, 77, 75], [79, 80, 78], [101, 102, 100], [105, 106, 104], [250, 252, 248], [225, 220]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_all_pairs = []\n",
    "\n",
    "for el in everything_pairs:\n",
    "    \n",
    "    check_prev = True\n",
    "    for e in el:\n",
    "        for ef in new_all_pairs:\n",
    "\n",
    "            if e in ef:\n",
    "                \n",
    "                if len(el) > len(ef):\n",
    "                    continue\n",
    "                \n",
    "                if len(el) < len(ef):\n",
    "                    check_prev = False\n",
    "                    break\n",
    "                    \n",
    "                this_std = np.std(list(el))\n",
    "                that_std = np.std(list(ef))\n",
    "                \n",
    "                if this_std < that_std:\n",
    "                    continue\n",
    "                    \n",
    "                check_prev = False\n",
    "                break\n",
    "                \n",
    "        if not check_prev:\n",
    "            break\n",
    "    \n",
    "    if check_prev:\n",
    "        new_all_pairs.append(el)\n",
    "                \n",
    "print(new_all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for pair in new_all_pairs:\n",
    "    counter += len(pair)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import core.mosyn as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('iadhore_plus_motifs_restr.yaml', 'r') as stream:\n",
    "    restructured_iadhore = yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iadhore_with_motifs_pair = cm.align_motifs_in_synteny(restructured_iadhore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('iadhore_plus_motifs_pair.yaml', 'w') as stream:\n",
    "    yaml.dump(iadhore_with_motifs_pair, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count0 = 0\n",
    "count1 = 0\n",
    "\n",
    "for key, value in iadhore_with_motifs_pair.items():\n",
    "    for ke, val in value.items():\n",
    "        for k in val.keys():\n",
    "            \n",
    "            if k == \"motifs\":\n",
    "                for pair in val[k]:\n",
    "                    for p in pair:\n",
    "                        count1 += 1\n",
    "                continue\n",
    "            \n",
    "            if \"motifs\" not in val[k].keys():\n",
    "                continue\n",
    "\n",
    "            for motif in val[k][\"motifs\"]:\n",
    "                count0 += 1\n",
    "                \n",
    "print(count0, count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import core.mosyn as cm\n",
    "import prep.iadhore as pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iadhore_dict = pi.iadhore_result_folder_to_dict(\"/media/ihsan/DATA/THESIS/MISC/TEMP/ADHORE/Drosophila/\")\n",
    "iadhore_dict = pi.get_complete_synteny_dict(iadhore_dict)\n",
    "iadhore_dict_with_locations = cm.add_location_to_iadhore_synteny(iadhore_dict, \"/media/ihsan/DATA/THESIS/MATERIAL/Drosophila/GTF/\")\n",
    "iadhore_dict_with_motifs = cm.add_motifs_into_synteny(iadhore_dict_with_locations, \"/media/ihsan/DATA/THESIS/RUN/PREP/Drosophila/storm/17/holohan_exp/GTF/\")\n",
    "restructured_iadhore = cm.restructure_iadhore_dict_to_position(iadhore_dict_with_motifs)\n",
    "iadhore_with_motifs_pair = cm.align_motifs_in_synteny(restructured_iadhore)\n",
    "synteny_motifs_complete = cm.get_complete_motifs_synteny(iadhore_with_motifs_pair)\n",
    "\n",
    "cm.dump_aligned_motifs_to_flat_synteny(synteny_motifs_complete, \"flat_synteny_motifs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count0 = 0\n",
    "count1 = 0\n",
    "\n",
    "for key, value in iadhore_with_motifs_pair.items():\n",
    "    for ke, val in value.items():\n",
    "        for k in val.keys():\n",
    "            \n",
    "            if k == \"motifs\":\n",
    "                for pair in val[k]:\n",
    "                    for p in pair:\n",
    "                        count1 += 1\n",
    "                continue\n",
    "            \n",
    "for key, value in iadhore_dict_with_motifs.items():\n",
    "    for k, v in value[\"segments\"].items():\n",
    "        for k0, v0 in v[\"elements\"].items():\n",
    "            if \"motifs\" not in v0.keys():\n",
    "                continue\n",
    "            count0 += len(v0[\"motifs\"])\n",
    "                \n",
    "print(count0, count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('synteny_motifs.yaml', 'w') as stream:\n",
    "    yaml.dump(iadhore_with_motifs_pair, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('synteny_motifs_and_loops_1.yaml', 'w') as stream:\n",
    "    yaml.dump(mosyn_dict, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for all condition\n",
    "\n",
    "fout = open(\"loops.csv\", 'w')\n",
    "loops_dictionary = dict()\n",
    "start_id = 1\n",
    "for key, value in sorted(mosyn_dict.items()):\n",
    "    \n",
    "    if \"loops\" not in value.keys():\n",
    "        continue\n",
    "    \n",
    "    this_loops = dict()\n",
    "    for loop in value[\"loops\"]:\n",
    "        \n",
    "        this_key = (loop[\"genome\"], loop[\"chromosome\"], loop[\"start\"])\n",
    "        this_loops[this_key] = loop\n",
    "        \n",
    "    for ke, val in sorted(this_loops.items()):\n",
    "        loops_dictionary[start_id] = val\n",
    "        loops_dictionary[start_id][\"multiplicon\"] = key\n",
    "        start_id += 1\n",
    "\n",
    "print(\"loop_id\", \"synteny_id\", \"genome\", \"chromosome\", \"first\", \"last\", \"start\", \"end\", sep=\",\", file=fout)\n",
    "selected_keys = [\"multiplicon\", \"genome\", \"chromosome\", \"first\", \"last\", \"start\", \"end\"]\n",
    "for key, value in sorted(loops_dictionary.items()):\n",
    "    \n",
    "    print_values = [str(value[sk]) for sk in selected_keys]\n",
    "    print_values = \",\".join(print_values)\n",
    "    print(key, print_values, sep=\",\", file=fout)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we are identifying the loops\n",
    "with open('/media/ihsan/DATA/THESIS/RESULT/Primary/Trichinella/DIAMOND/holohan_exp/synteny.yaml', 'r') as stream:\n",
    "    mosyn_dict = yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key, value in sorted(mosyn_dict.items()):\n",
    "    \n",
    "    # first check the occurence of \"motifs\" key\n",
    "    key_counter = 0\n",
    "    for ke, val in sorted(value.items()):\n",
    "        \n",
    "        if \"motifs\" in val.keys():\n",
    "            key_counter += 1\n",
    "    \n",
    "    if key_counter < 2:\n",
    "        continue\n",
    "        \n",
    "    # then get list of segment\n",
    "    set_of_segments = set()\n",
    "    for ke, val in sorted(value.items()):\n",
    "        for k in val.keys():\n",
    "            if k == \"motifs\":\n",
    "                continue\n",
    "            v = val[k]\n",
    "            set_of_segments.add((v[\"genome\"], v[\"chromosome\"]))\n",
    "    \n",
    "    loops = []\n",
    "    for seg in sorted(set_of_segments):\n",
    "        \n",
    "        current_strand = None\n",
    "        current_motif = None\n",
    "        current_pair = None\n",
    "        current_size = 0\n",
    "        \n",
    "        inverse_strand = None\n",
    "        inverse_motif = None\n",
    "        inverse_pair = None\n",
    "        inverse_size = 0\n",
    "        \n",
    "        for ke, val in sorted(value.items()):\n",
    "            if \"motifs\" in val.keys():\n",
    "                for pair in val[\"motifs\"]:\n",
    "                    for m in pair:\n",
    "                        m_genome = m[\"genome\"]\n",
    "                        m_chromosome = m[\"chromosome\"]\n",
    "                        m_gc = (m_genome, m_chromosome)\n",
    "                    \n",
    "                        if not (m_gc == seg):\n",
    "                            continue\n",
    "                        \n",
    "                        if not current_motif:\n",
    "                            current_strand = m[\"strand\"]\n",
    "                            current_motif = m\n",
    "                            continue\n",
    "                            \n",
    "                        loc = [current_motif[\"start\"], current_motif[\"end\"], m[\"start\"], m[\"end\"]]\n",
    "                        start = min(loc)\n",
    "                        end = max(loc)\n",
    "                        size = end - start\n",
    "                            \n",
    "                        if current_strand != m[\"strand\"]:\n",
    "                            \n",
    "                            if not inverse_motif:\n",
    "                                inverse_strand = m[\"strand\"]\n",
    "                                inverse_motif = m\n",
    "                            \n",
    "                            if (not current_pair) or (size > current_size):\n",
    "                                current_pair = m\n",
    "                                current_size = size\n",
    "                                continue\n",
    "                                \n",
    "                        else:\n",
    "                            \n",
    "                            if (not inverse_pair) or (size > inverse_size):\n",
    "                                inverse_pair = m\n",
    "                                inverse_size = size\n",
    "                                continue\n",
    "        \n",
    "        current_loop = None\n",
    "        if current_motif and current_pair:\n",
    "            current_loc = [current_motif[\"start\"], current_motif[\"end\"], current_pair[\"start\"], current_pair[\"end\"]]\n",
    "            current_motif_id = sorted([current_motif[\"motif\"], current_pair[\"motif\"]])\n",
    "            current_start = min(current_loc)\n",
    "            current_end = max(current_loc)\n",
    "            current_loop = {\"start\": current_start, \"end\": current_end, \n",
    "                    \"chromosome\": current_motif[\"chromosome\"], \"genome\": current_motif[\"genome\"], \n",
    "                   \"first\": current_motif_id[0], \"last\": current_motif_id[1]}\n",
    "            \n",
    "        inverse_loop = None                      \n",
    "        if inverse_motif and inverse_pair:\n",
    "            inverse_loc = [inverse_motif[\"start\"], inverse_motif[\"end\"], inverse_pair[\"start\"], inverse_pair[\"end\"]]\n",
    "            inverse_motif_id = sorted([inverse_motif[\"motif\"], inverse_pair[\"motif\"]])\n",
    "            inverse_start = min(inverse_loc)\n",
    "            inverse_end = max(inverse_loc)\n",
    "            inverse_loop = {\"start\": inverse_start, \"end\": inverse_end, \n",
    "                    \"chromosome\": inverse_motif[\"chromosome\"], \"genome\": inverse_motif[\"genome\"],\n",
    "                   \"first\": inverse_motif_id[0], \"last\": inverse_motif_id[1]}\n",
    "            \n",
    "        if current_loop:\n",
    "            loops.append(current_loop)\n",
    "            if inverse_loop:\n",
    "                if current_start <= inverse_start and current_end >= inverse_end:\n",
    "                    continue\n",
    "                loops.append(inverse_loop)\n",
    "                \n",
    "    if loops:\n",
    "        mosyn_dict[key][\"loops\"] = loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for complete synteny only\n",
    "\n",
    "fout = open(\"trichinella_loops_complete.csv\", 'w')\n",
    "loops_dictionary = dict()\n",
    "start_id = 1\n",
    "for key, value in sorted(mosyn_dict.items()):\n",
    "    \n",
    "    if \"loops\" not in value.keys():\n",
    "        continue\n",
    "    \n",
    "    genome_chromosome_set = set()\n",
    "    for loop in value[\"loops\"]:\n",
    "        \n",
    "        genome_chromosome_set.add((loop[\"genome\"], loop[\"chromosome\"]))\n",
    "        \n",
    "    num_of_element = len(value[\"loops\"]) / len(genome_chromosome_set)\n",
    "    num_of_element = int(num_of_element)\n",
    "    \n",
    "    pair_loops = dict()\n",
    "    for i in range(num_of_element):\n",
    "        pair_loops[start_id] = []\n",
    "        for j in range(i, len(value[\"loops\"]), num_of_element):\n",
    "            pair_loops[start_id].append(value[\"loops\"][j])\n",
    "        start_id += 1\n",
    "            \n",
    "    loops_dictionary[key] = pair_loops\n",
    "\n",
    "selected_keys = [\"genome\", \"chromosome\", \"first\", \"last\", \"start\", \"end\"]\n",
    "for key, value in sorted(loops_dictionary.items()):\n",
    "    \n",
    "    for ke, val in sorted(value.items()):\n",
    "        print_values = []\n",
    "        for v in val:\n",
    "            for sk in selected_keys:\n",
    "                print_values.append(str(v[sk]))\n",
    "                \n",
    "        print_str = \",\".join(print_values)\n",
    "        print(ke, key, print_str, sep=\",\", file=fout)\n",
    "        \n",
    "fout.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def identify_loops_in_synteny(motifs_synteny_yaml_file, min_length=10000, max_length=1000000):\n",
    "\n",
    "    with open(motifs_synteny_yaml_file, 'r') as stream:\n",
    "        mosyn_dict = yaml.load(stream)\n",
    "\n",
    "    for key, value in sorted(mosyn_dict.items()):\n",
    "\n",
    "        # first check the occurence of \"motifs\" key\n",
    "        key_counter = 0\n",
    "        for ke, val in sorted(value.items()):\n",
    "\n",
    "            if \"motifs\" in val.keys():\n",
    "                key_counter += 1\n",
    "\n",
    "        if key_counter < 2:\n",
    "            continue\n",
    "\n",
    "        # then get list of segment\n",
    "        set_of_segments = set()\n",
    "        for ke, val in sorted(value.items()):\n",
    "            for k in val.keys():\n",
    "                if k == \"motifs\":\n",
    "                    continue\n",
    "                v = val[k]\n",
    "                set_of_segments.add((v[\"genome\"], v[\"chromosome\"]))\n",
    "\n",
    "        loops = []\n",
    "        \n",
    "        for seg in sorted(set_of_segments):\n",
    "            for ke, val in sorted(value.items()):\n",
    "                if \"motifs\" in val.keys():\n",
    "                    for pair in val[\"motifs\"]:\n",
    "                        for m in pair:\n",
    "                            m_genome = m[\"genome\"]\n",
    "                            m_chromosome = m[\"chromosome\"]\n",
    "                            m_gc = (m_genome, m_chromosome)\n",
    "\n",
    "                            if not (m_gc == seg):\n",
    "                                continue\n",
    "                                    \n",
    "                            current_motif = m\n",
    "                            current_strand = m[\"strand\"]\n",
    "                            current_pair = None\n",
    "                            current_size = 0\n",
    "                            \n",
    "                            for kf, wal in sorted(value.items()):\n",
    "                                if \"motifs\" in wal.keys():\n",
    "                                    \n",
    "                                    for qair in wal[\"motifs\"]:\n",
    "                                        for n in qair:\n",
    "\n",
    "                                            n_genome = n[\"genome\"]\n",
    "                                            n_chromosome = n[\"chromosome\"]\n",
    "                                            n_gc = (n_genome, n_chromosome)\n",
    "\n",
    "                                            if not (n_gc == seg):\n",
    "                                                continue\n",
    "\n",
    "                                            if current_strand == n[\"strand\"]:\n",
    "                                                break\n",
    "\n",
    "                                            loc = [current_motif[\"start\"], current_motif[\"end\"], n[\"start\"], n[\"end\"]]\n",
    "                                            start = min(loc)\n",
    "                                            end = max(loc)\n",
    "                                            size = end - start\n",
    "\n",
    "                                            if min_length <= size <= max_length:\n",
    "\n",
    "                                                if (not current_pair) or (size > current_size):\n",
    "                                                    current_pair = n\n",
    "                                                    current_size = size\n",
    "                                                    break\n",
    "                                                    \n",
    "                                            \n",
    "                            if current_pair:\n",
    "                                \n",
    "                                current_loc = [current_motif[\"start\"], current_motif[\"end\"], \n",
    "                                               current_pair[\"start\"], current_pair[\"end\"]]\n",
    "                                current_motif_id = sorted([current_motif[\"motif\"], current_pair[\"motif\"]])\n",
    "                                current_start = min(current_loc)\n",
    "                                current_end = max(current_loc)\n",
    "                                current_loop = {\"start\": current_start, \"end\": current_end,\n",
    "                                                \"chromosome\": current_motif[\"chromosome\"], \"genome\": current_motif[\"genome\"],\n",
    "                                                \"first\": current_motif_id[0], \"last\": current_motif_id[1], \"size\": current_size}\n",
    "                                \n",
    "                                loops.append(current_loop)\n",
    "        \n",
    "        if not loops:\n",
    "            continue\n",
    "            \n",
    "        size_loops = dict()\n",
    "        for loop in loops:\n",
    "            \n",
    "            gc_key = (loop[\"genome\"], loop[\"chromosome\"])\n",
    "            if gc_key not in size_loops.keys():\n",
    "                size_loops[gc_key] = dict()\n",
    "                \n",
    "            sz_key = loop[\"size\"]\n",
    "            size_loops[gc_key][sz_key] = loop\n",
    "            \n",
    "            \n",
    "        selected_loops = []\n",
    "        for k, v in sorted(size_loops.items()):\n",
    "            for k0, v0 in sorted(v.items(), reverse=True):\n",
    "                \n",
    "                if not selected_loops:\n",
    "                    selected_loops.append(v0)\n",
    "                    continue\n",
    "\n",
    "                check_insert = True\n",
    "                for sl in selected_loops:\n",
    "                    if sl[\"genome\"] == v0[\"genome\"] and sl[\"chromosome\"] == v0[\"chromosome\"]:\n",
    "                        if v0[\"start\"] >= sl[\"start\"] and v0[\"end\"] <= sl[\"end\"]:\n",
    "                            check_insert = False\n",
    "                            break\n",
    "\n",
    "                if check_insert:\n",
    "                    selected_loops.append(v0)\n",
    "                \n",
    "        mosyn_dict[key][\"loops\"] = selected_loops\n",
    "        \n",
    "    return mosyn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yaml_file = '/media/ihsan/DATA/THESIS/RESULT/Primary/Drosophila/DIAMOND/holohan_exp/synteny.yaml'\n",
    "\n",
    "synteny_loops = identify_loops_in_synteny(yaml_file, 70000, 700000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loops_summary_complete(synteny_loops_dict, outfile):\n",
    "    \n",
    "    fout = open(outfile, 'w')\n",
    "    loops_dictionary = dict()\n",
    "    start_id = 1\n",
    "    for key, value in sorted(synteny_loops_dict.items()):\n",
    "\n",
    "        if \"loops\" not in value.keys():\n",
    "            continue\n",
    "\n",
    "        genome_chromosome_set = set()\n",
    "        for loop in value[\"loops\"]:\n",
    "            genome_chromosome_set.add((loop[\"genome\"], loop[\"chromosome\"]))\n",
    "\n",
    "        num_of_element = len(value[\"loops\"]) / len(genome_chromosome_set)\n",
    "        num_of_element = int(num_of_element)\n",
    "\n",
    "        pair_loops = dict()\n",
    "        for i in range(num_of_element):\n",
    "            pair_loops[start_id] = []\n",
    "            for j in range(i, len(value[\"loops\"]), num_of_element):\n",
    "                pair_loops[start_id].append(value[\"loops\"][j])\n",
    "            start_id += 1\n",
    "\n",
    "        loops_dictionary[key] = pair_loops\n",
    "\n",
    "    selected_keys = [\"genome\", \"chromosome\", \"first\", \"last\", \"start\", \"end\"]\n",
    "    for key, value in sorted(loops_dictionary.items()):\n",
    "\n",
    "        for ke, val in sorted(value.items()):\n",
    "            print_values = []\n",
    "            for v in val:\n",
    "                for sk in selected_keys:\n",
    "                    print_values.append(str(v[sk]))\n",
    "\n",
    "            print_str = \",\".join(print_values)\n",
    "            print(ke, key, print_str, sep=\",\", file=fout)\n",
    "\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfile = \"drosophila_loops.csv\"\n",
    "\n",
    "get_loops_summary_complete(synteny_loops, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"drosophila_loops.yaml\", \"w\") as stream:\n",
    "    yaml.dump(synteny_loops, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_loops_in_synteny(motifs_synteny_yaml_file, min_length=10000, max_length=1000000):\n",
    "    \"\"\"\n",
    "    Identify k-mer to k-mer loops\n",
    "    :param motifs_synteny_yaml_file: MoSyn YAML output\n",
    "    :param min_length: The minimum length of the loops\n",
    "    :param max_length: The maximum length of the loops\n",
    "    :return: MoSyn dictionary with loops\n",
    "    \"\"\"\n",
    "\n",
    "    with open(motifs_synteny_yaml_file, 'r') as stream:\n",
    "        mosyn_dict = yaml.load(stream)\n",
    "\n",
    "    for key, value in sorted(mosyn_dict.items()):\n",
    "\n",
    "        key_counter = 0\n",
    "        for ke, val in sorted(value.items()):\n",
    "\n",
    "            if \"motifs\" in val.keys():\n",
    "                key_counter += 1\n",
    "\n",
    "        if key_counter < 2:\n",
    "            continue\n",
    "\n",
    "        loops_size = dict()\n",
    "        for ke, val in sorted(value.items()):\n",
    "            if \"motifs\" in val.keys():\n",
    "                for pair in val[\"motifs\"]:\n",
    "\n",
    "                    current_first = pair\n",
    "                    current_pos = ke\n",
    "                    current_strand = {(m[\"genome\"], m[\"chromosome\"]): m[\"strand\"] for m in pair}\n",
    "                    current_last = None\n",
    "                    current_size = 0\n",
    "                    last_pos = None\n",
    "                    current_gc = set([(m[\"genome\"], m[\"chromosome\"]) for m in pair])\n",
    "\n",
    "                    for ke0, val0 in sorted(value.items()):\n",
    "                        if \"motifs\" in val0.keys():\n",
    "                            for pair0 in val0[\"motifs\"]:\n",
    "\n",
    "                                pos_distance = ke0 - current_pos\n",
    "\n",
    "                                if pos_distance < 2:\n",
    "                                    break\n",
    "\n",
    "                                this_gc = set([(m[\"genome\"], m[\"chromosome\"]) for m in pair0])\n",
    "                                if not (current_gc == this_gc):\n",
    "                                    continue\n",
    "\n",
    "                                this_strand = {(m[\"genome\"], m[\"chromosome\"]): m[\"strand\"] for m in pair0}\n",
    "                                if current_strand == this_strand:\n",
    "                                    continue\n",
    "\n",
    "                                start = [m[\"start\"] for m in current_first]\n",
    "                                end = [m[\"start\"] for m in pair0]\n",
    "                                size_list = [abs(x-y) for x,y in zip(start, end)]\n",
    "                                avg_size = numpy.mean(size_list)\n",
    "\n",
    "                                if min_length <= avg_size <= max_length:\n",
    "\n",
    "                                    size = sum(size_list)\n",
    "\n",
    "                                    if (not current_last) or (size > current_size):\n",
    "                                        current_last = pair0\n",
    "                                        current_size = size\n",
    "                                        last_pos = ke0\n",
    "\n",
    "                    if current_last:\n",
    "\n",
    "                        loop = {\n",
    "                            \"first\": current_first,\n",
    "                            \"last\": current_last,\n",
    "                            \"first_pos\": current_pos,\n",
    "                            \"last_pos\": last_pos\n",
    "                        }\n",
    "\n",
    "                        loop_size = int(current_size)\n",
    "                        \n",
    "                        if loop_size not in loops_size.keys():\n",
    "                            loops_size[loop_size] = []\n",
    "                        \n",
    "                        loops_size[loop_size].append(loop)\n",
    "\n",
    "        if not loops_size:\n",
    "            continue\n",
    "\n",
    "        selected_loops = []\n",
    "        for loop_size in sorted(loops_size.keys(), reverse=True):\n",
    "            for loop in loops_size[loop_size]:\n",
    "\n",
    "                if not selected_loops:\n",
    "                    selected_loops.append(loop)\n",
    "                    continue\n",
    "\n",
    "                check_select = True\n",
    "                for sl in selected_loops:\n",
    "\n",
    "                    if loop[\"first_pos\"] >= sl[\"first_pos\"] and loop[\"last_pos\"] <= sl[\"last_pos\"]:\n",
    "                        check_select = False\n",
    "                        break\n",
    "\n",
    "                if check_select:\n",
    "                    selected_loops.append(loop)\n",
    "\n",
    "        pos_loops = dict()\n",
    "        for loop in selected_loops:\n",
    "            pos_key = (loop[\"first_pos\"], loop[\"last_pos\"])\n",
    "            pos_loops[pos_key] = loop\n",
    "\n",
    "        loops = []\n",
    "        for pos, loop in sorted(pos_loops.items()):\n",
    "            loops.append(loop)\n",
    "\n",
    "        if loops:\n",
    "            mosyn_dict[key][\"loops\"] = loops\n",
    "\n",
    "    return mosyn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yaml_file = '/media/ihsan/DATA/THESIS/RESULT/Primary/Drosophila/DIAMOND/holohan_exp/synteny.yaml'\n",
    "\n",
    "synteny_loops = identify_loops_in_synteny(yaml_file, 80000, 800000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"drosophila_loops.yaml\", \"w\") as stream:\n",
    "    yaml.dump(synteny_loops, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_loops_to_csv(mosyn_loops_dict, outfile):\n",
    "    \"\"\"\n",
    "    Print MoSyn loops to csv file\n",
    "    :param mosyn_loops_dict: MoSyn loops dictionary\n",
    "    :param outfile: .csv file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    fout = open(outfile, 'w')\n",
    "\n",
    "    start_index = 1\n",
    "    for key, value in sorted(mosyn_loops_dict.items()):\n",
    "\n",
    "        if \"loops\" not in value.keys():\n",
    "            continue\n",
    "\n",
    "        for loop in value[\"loops\"]:\n",
    "\n",
    "            print_value = []\n",
    "            segments = sorted([(m[\"genome\"], m[\"chromosome\"]) for m in loop[\"first\"]])\n",
    "            for seg in segments:\n",
    "                l_motifs = [m for m in loop[\"first\"]+loop[\"last\"] if (m[\"genome\"], m[\"chromosome\"]) == seg]\n",
    "                l_start = [m[\"start\"] for m in l_motifs]\n",
    "                l_end = [m[\"end\"] for m in l_motifs]\n",
    "                l_loc = sorted(l_start+l_end)\n",
    "                l_id = sorted([m[\"motif\"] for m in l_motifs])\n",
    "                print_value += [seg[0], seg[-1], l_id[0], l_id[-1], l_loc[0], l_loc[-1]]\n",
    "\n",
    "            print_string = [str(p) for p in print_value]\n",
    "\n",
    "            print(start_index, key, \",\".join(print_string), sep=\",\", file=fout)\n",
    "            start_index += 1\n",
    "\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_loops_to_csv(synteny_loops, \"drosophila.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from misc.bash import create_loop_bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_storm_bash(\"/media/ihsan/DATA/THESIS/PIPELINE/ms-core.py\", \n",
    "                  \"/media/ihsan/Leere_Platte/ASAP/MATERIAL/Caenorhabditis/Genome/\", \n",
    "                  \"/media/ihsan/Leere_Platte/ASAP/MATERIAL/PWM/\",\n",
    "                  \"/media/ihsan/Leere_Platte/ASAP/RUN/STORM/Caenorhabditis/\",\n",
    "                  \"/media/ihsan/Leere_Platte/ASAP/storm_caenorhabditis.sh\",\n",
    "                  15, 19, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = os.path.split(\"/media/ihsan/Leere_Platte/ASAP/storm_drosophila.sh\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_folder = \"/media/ihsan/Leere_Platte/ASAP/RUN/\" \n",
    "material_folder = \"/media/ihsan/Leere_Platte/ASAP/MATERIAL/\" \n",
    "output_folder = \"/media/ihsan/Leere_Platte/ASAP/RESULT/\" \n",
    "pwm_names = [\"holohan_exp\"]\n",
    "list_genus = [\"Drosophila\", \"Trichinella\", \"Caenorhabditis\"] \n",
    "list_alignment = [\"BLAST\", \"DIAMOND\"] \n",
    "range_score = [i for i in range(15, 20)] \n",
    "script_file = \"/media/ihsan/DATA/THESIS/PIPELINE/ms-core.py\" \n",
    "bash_outfile = \"/media/ihsan/Leere_Platte/ASAP/mosyn.sh\"\n",
    "\n",
    "create_mosyn_bash(result_folder, material_folder, output_folder, pwm_names, \n",
    "                  list_genus, list_alignment, range_score, script_file, bash_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_folder = \"/media/ihsan/Leere_Platte/ASAP/RESULT/\" \n",
    "output_folder = \"/media/ihsan/Leere_Platte/ASAP/ANALYSIS/LOOP/\"\n",
    "\n",
    "pwm_names = [\"holohan_exp\"]\n",
    "list_genus = [\"Trichinella\", \"Caenorhabditis\"] \n",
    "list_alignment = [\"BLAST\", \"DIAMOND\"] \n",
    "range_score = [i for i in range(15, 20)] \n",
    "script_file = \"/media/ihsan/DATA/THESIS/PIPELINE/ms-analysis.py\" \n",
    "bash_outfile = \"/media/ihsan/Leere_Platte/ASAP/idloop.sh\"\n",
    "\n",
    "create_loop_bash(result_folder, output_folder,\n",
    "                 pwm_names, list_genus, list_alignment, range_score, script_file, bash_outfile, 0, 2000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_mosyn_short_summary(infolder, outfile, genus_index=-5, alignment_index=-4, score_index=-3, pwm_index=-2):\n",
    "    \"\"\"\n",
    "    Generate detailed i-ADHoRe summary.\n",
    "    Result structure Genus -> Alignment -> Result\n",
    "    GTF structure Material -> Genus -> GTF\n",
    "    :param material_folder: Folder containing GTF folder\n",
    "    :param infolder: Folder containing i-ADHoRe result\n",
    "    :param outfile: Output folder\n",
    "    :param genus_index: Genus folder index from result\n",
    "    :param alignment_index: Alignment folder index from result\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    material_folder = check_folder_path(material_folder)\n",
    "\n",
    "    fout = open(outfile, 'w')\n",
    "\n",
    "    print(\"Genus\", \"Alignment\", \"Number_of_Synteny\", \"Number_of_Genes_in_Synteny\",\n",
    "          \"Average_Number_of_Genes_per_Synteny\", \"Average_Length_per_Synteny\",\n",
    "          sep=\",\", file=fout)\n",
    "\n",
    "    infolder = check_folder_path(infolder)\n",
    "    for synt in glob.glob(infolder + '**/synteny.yaml', recursive=True):\n",
    "\n",
    "        path_elem = mult.split('/')\n",
    "        genus = path_elem[genus_index]\n",
    "        alignment = path_elem[alignment_index]\n",
    "        pwm = path_elem[pwm_index]\n",
    "        score = path_elem[score_index]\n",
    "\n",
    "        with open(synt, 'r') as stream:\n",
    "            iadhore_dict_with_motifs = yaml.load(stream)\n",
    "\n",
    "        synteny_length = 0\n",
    "        synteny_genes = 0\n",
    "        num_of_mult = 0\n",
    "\n",
    "        set_of_genes = set()\n",
    "\n",
    "        for key, value in iadhore_dict_with_motifs.items():\n",
    "\n",
    "            number_of_segments = 0\n",
    "            mult_genes = 0\n",
    "            mult_length = 0\n",
    "\n",
    "            for ke, val in value[\"segments\"].items():\n",
    "                number_of_segments += 1\n",
    "                length = abs(val[\"start\"] - val[\"end\"])\n",
    "                mult_length += length\n",
    "                mult_genes += len(val[\"elements\"])\n",
    "\n",
    "                for v in val[\"elements\"].values():\n",
    "                    set_of_genes.add(v[\"gene\"])\n",
    "\n",
    "            mult_avg_len = mult_length / number_of_segments\n",
    "            mult_avg_genes = mult_genes / number_of_segments\n",
    "\n",
    "            synteny_length += mult_avg_len\n",
    "            synteny_genes += mult_avg_genes\n",
    "            num_of_mult += 1\n",
    "\n",
    "        nr_genes = len(set_of_genes)\n",
    "        synteny_avg_length = synteny_length / num_of_mult\n",
    "        synteny_avg_genes = synteny_genes / num_of_mult\n",
    "\n",
    "        print(genus, alignment, num_of_mult, nr_genes, synteny_avg_genes, synteny_avg_length, sep=\",\", file=fout)\n",
    "\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_short_iadhore_summary(infolder, outfile, material_folder, genus_index=-3, alignment_index=-2):\n",
    "    \"\"\"\n",
    "    Generate detailed i-ADHoRe summary.\n",
    "    Result structure Genus -> Alignment -> Result\n",
    "    GTF structure Material -> Genus -> GTF\n",
    "    :param material_folder: Folder containing GTF folder\n",
    "    :param infolder: Folder containing i-ADHoRe result\n",
    "    :param outfile: Output folder\n",
    "    :param genus_index: Genus folder index from result\n",
    "    :param alignment_index: Alignment folder index from result\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    material_folder = check_folder_path(material_folder)\n",
    "\n",
    "    fout = open(outfile, 'w')\n",
    "\n",
    "    print(\"Genus\", \"Alignment\", \"Number_of_Synteny\", \"Number_of_Genes_in_Synteny\",\n",
    "          \"Average_Number_of_Genes_per_Synteny\", \"Average_Length_per_Synteny\",\n",
    "          sep=\",\", file=fout)\n",
    "\n",
    "    infolder = check_folder_path(infolder)\n",
    "    for mult in glob.glob(infolder + '**/multiplicons.txt', recursive=True):\n",
    "\n",
    "        path_elem = mult.split('/')\n",
    "        genus = path_elem[genus_index]\n",
    "        alignment = path_elem[alignment_index]\n",
    "\n",
    "        gtf_folder = material_folder + \"/\".join([genus, \"GTF\"])\n",
    "        gtf_folder = check_folder_path(gtf_folder)\n",
    "\n",
    "        iadhore_result = os.path.dirname(mult)\n",
    "        iadhore_dict = pi.iadhore_result_folder_to_dict(iadhore_result)\n",
    "        iadhore_dict_with_location = cm.add_location_to_iadhore_synteny(iadhore_dict, gtf_folder)\n",
    "\n",
    "        synteny_length = 0\n",
    "        synteny_genes = 0\n",
    "        num_of_mult = 0\n",
    "\n",
    "        set_of_genes = set()\n",
    "\n",
    "        for key, value in iadhore_dict_with_location.items():\n",
    "\n",
    "            number_of_segments = 0\n",
    "            mult_genes = 0\n",
    "            mult_length = 0\n",
    "\n",
    "            for ke, val in value[\"segments\"].items():\n",
    "                number_of_segments += 1\n",
    "                length = abs(val[\"start\"] - val[\"end\"])\n",
    "                mult_length += length\n",
    "                mult_genes += len(val[\"elements\"])\n",
    "\n",
    "                for v in val[\"elements\"].values():\n",
    "                    set_of_genes.add(v[\"gene\"])\n",
    "\n",
    "            mult_avg_len = mult_length / number_of_segments\n",
    "            mult_avg_genes = mult_genes / number_of_segments\n",
    "\n",
    "            synteny_length += mult_avg_len\n",
    "            synteny_genes += mult_avg_genes\n",
    "            num_of_mult += 1\n",
    "\n",
    "        nr_genes = len(set_of_genes)\n",
    "        synteny_avg_length = synteny_length / num_of_mult\n",
    "        synteny_avg_genes = synteny_genes / num_of_mult\n",
    "\n",
    "        print(genus, alignment, num_of_mult, nr_genes, synteny_avg_genes, synteny_avg_length, sep=\",\", file=fout)\n",
    "\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_mosyn_summary(infolder, genus_index=-5, alignment_index=-4, score_index=-3, pwm_index=-2):\n",
    "    \"\"\"\n",
    "    Generate MoSyn summary\n",
    "    :param infolder: Input folder containing result\n",
    "    :param genus_index: Genus index folder relative to result file\n",
    "    :param alignment_index: Alignment index folder relative to result file\n",
    "    :param score_index: Score index folder relative to result file\n",
    "    :param pwm_index: PWM index folder relative to result file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    outfile = \"mosyn_detail_summary.csv\"\n",
    "    outfile0 = \"mosyn_short_summary.csv\"\n",
    "\n",
    "    fout = open(outfile, 'w')\n",
    "    fout0 = open(outfile0, 'w')\n",
    "\n",
    "    print(\"Genus\", \"Alignment\", \"Score\", \"PWM\", \"Synteny_ID\", \"Number_of_Segments\", \"Number_of_Genes\", \"Number_of_CTCF\",\n",
    "          \"Total_Length\", sep=\",\", file=fout)\n",
    "\n",
    "    print(\"Genus\", \"Alignment\", \"Score\", \"PWM\", \"Number_of_Synteny\", \"Number_of_Genes_in_Synteny\",\n",
    "          \"Number_of_Synteny_containing_Motifs\", \"Number_of_Motifs_in_Synteny\",\n",
    "          \"Average_Number_of_Genes_per_Synteny_per_Species\", \"Average_Length_per_Synteny_per_Species\",\n",
    "          \"Average_Number_of_Motifs_per_Synteny_per_Species\", sep=\",\", file=fout0)\n",
    "\n",
    "    infolder = check_folder_path(infolder)\n",
    "    for synt in glob.glob(infolder + '**/synteny.yaml', recursive=True):\n",
    "\n",
    "        path_elem = synt.split('/')\n",
    "        genus = path_elem[genus_index]\n",
    "        alignment = path_elem[alignment_index]\n",
    "        score = path_elem[score_index]\n",
    "        pwm = path_elem[pwm_index]\n",
    "\n",
    "        with open(synt, 'r') as stream:\n",
    "            iadhore_dict_with_motifs = yaml.load(stream)\n",
    "\n",
    "        synteny_length = 0\n",
    "        synteny_genes = 0\n",
    "        num_of_mult = 0\n",
    "\n",
    "        synteny_motifs = 0\n",
    "        synteny_contain = 0\n",
    "\n",
    "        set_of_genes = set()\n",
    "        set_of_motifs = set()\n",
    "\n",
    "        for key, value in sorted(iadhore_dict_with_motifs.items()):\n",
    "\n",
    "            num_of_mult += 1\n",
    "\n",
    "            position_keys = sorted([k for k in value.keys() if k != \"loops\"])\n",
    "            avg_mult_genes = len(position_keys)\n",
    "\n",
    "            segment_keys = sorted([k for k in value[position_keys[0]].keys() if k != \"motifs\"])\n",
    "            num_of_segments = len(segment_keys)\n",
    "\n",
    "            mult_length = 0\n",
    "            for sk in segment_keys:\n",
    "                s_loc = [value[position_keys[0]][sk][\"start\"], value[position_keys[0]][sk][\"end\"],\n",
    "                         value[position_keys[-1]][sk][\"start\"], value[position_keys[-1]][sk][\"end\"]]\n",
    "                s_start = min(s_loc)\n",
    "                s_end = max(s_loc)\n",
    "                s_length = abs(s_end - s_start)\n",
    "                mult_length += s_length\n",
    "            avg_mult_length = mult_length / num_of_segments\n",
    "\n",
    "            mult_motifs = 0\n",
    "            mult_genes = 0\n",
    "\n",
    "            avg_mult_motifs = 0\n",
    "\n",
    "            check_contain = False\n",
    "\n",
    "            for ke, val in value.items():\n",
    "\n",
    "                if ke == \"loops\":\n",
    "                    continue\n",
    "\n",
    "                for k, v in val.items():\n",
    "\n",
    "                    if k == \"motifs\":\n",
    "\n",
    "                        if not check_contain:\n",
    "                            check_contain = True\n",
    "\n",
    "                        avg_mult_motifs += len(v)\n",
    "                        for pair in v:\n",
    "                            for motif in pair:\n",
    "                                mult_motifs += 1\n",
    "                                set_of_motifs.add(motif[\"motif\"])\n",
    "\n",
    "                    else:\n",
    "                        mult_genes += 1\n",
    "                        set_of_genes.add(v[\"gene\"])\n",
    "\n",
    "            alternative_mult_genes = avg_mult_genes * num_of_segments\n",
    "            alternative_mult_motifs = avg_mult_motifs * num_of_segments\n",
    "\n",
    "            assert alternative_mult_genes == mult_genes\n",
    "            assert alternative_mult_motifs == mult_motifs\n",
    "\n",
    "            if check_contain:\n",
    "                synteny_contain += 1\n",
    "\n",
    "            synteny_length += avg_mult_length\n",
    "            synteny_genes += avg_mult_genes\n",
    "            synteny_motifs += avg_mult_motifs\n",
    "\n",
    "            print(genus, alignment, score, pwm, key, num_of_segments, mult_genes, mult_motifs, mult_length,\n",
    "                  sep=\",\", file=fout)\n",
    "\n",
    "        nr_genes = len(set_of_genes)\n",
    "        nr_motifs = len(set_of_motifs)\n",
    "\n",
    "        avg_synteny_length = synteny_length / num_of_mult\n",
    "        avg_synteny_genes = synteny_genes / num_of_mult\n",
    "        avg_synteny_motifs = synteny_motifs / synteny_contain\n",
    "\n",
    "        print(genus, alignment, score, pwm, num_of_mult, nr_genes, synteny_contain, nr_motifs,\n",
    "              avg_synteny_genes, avg_synteny_length, avg_synteny_motifs, sep=\",\", file=fout0)\n",
    "\n",
    "    fout.close()\n",
    "    fout0.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
