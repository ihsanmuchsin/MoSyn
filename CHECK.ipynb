{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"/media/ihsan/DATA/THESIS/MISC/TEMP/ADHORE/Drosophila/synteny.json\"\n",
    "with open(json_file, 'r') as f:\n",
    "    json_dict = json.load(f)\n",
    "    \n",
    "print (len(json_dict[\"1\"][\"segments\"][\"1\"][\"elements\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yaml_file = \"/media/ihsan/DATA/THESIS/MISC/TEMP/ADHORE/Drosophila/synteny.yaml\"\n",
    "with open(yaml_file, 'r') as f:\n",
    "    yaml_dict = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (len(yaml_dict[1][\"segments\"][1][\"elements\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = \"/media/ihsan/DATA/THESIS/MISC/TEMP/ADHORE/Drosophila/synteny.pickle\"\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    pickle_dict = pickle.load(f)\n",
    "    \n",
    "print (len(pickle_dict[1][\"segments\"][1][\"elements\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_species = ['Caenorhabditis', 'Drosophila', 'Trichinella']\n",
    "all_alignment = ['BLAST', 'DIAMOND']\n",
    "for species in all_species:\n",
    "    for alignment in all_alignment:\n",
    "        the_folder = '/media/ihsan/DATA/THESIS/RUN/PREP/'+species+'/iadhore/family/'+alignment\n",
    "        os.makedirs(the_folder)\n",
    "        print(the_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_species = ['Caenorhabditis', 'Drosophila', 'Trichinella']\n",
    "all_alignment = ['BLAST', 'DIAMOND']\n",
    "for species in all_species:\n",
    "    for alignment in all_alignment:\n",
    "        the_folder = '/media/ihsan/DATA/THESIS/RUN/PREP/'+species+'/orthofinder/Orthogroups_gene/'+alignment+'/Orthogroups.txt'\n",
    "        print(the_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_species = ['Caenorhabditis', 'Drosophila', 'Trichinella']\n",
    "all_alignment = ['BLAST', 'DIAMOND']\n",
    "for species in all_species:\n",
    "    for alignment in all_alignment:\n",
    "        the_folder = '/media/ihsan/DATA/THESIS/RUN/PREP/'+species+'/iadhore/family/'+alignment+'/iadhore_family.tsv'\n",
    "        print(the_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_species = ['Caenorhabditis', 'Drosophila', 'Trichinella']\n",
    "all_alignment = ['BLAST', 'DIAMOND']\n",
    "program = 'python'\n",
    "command = '/media/ihsan/DATA/THESIS/PIPELINE/ms-prep.py'\n",
    "subcommand = 'og2fam'\n",
    "\n",
    "for species in all_species:\n",
    "    for alignment in all_alignment:\n",
    "        infile = '/media/ihsan/DATA/THESIS/RUN/PREP/'+species+'/orthofinder/Orthogroups_gene/'+alignment+'/Orthogroups.txt'\n",
    "        outfile = '/media/ihsan/DATA/THESIS/RUN/PREP/'+species+'/iadhore/family/'+alignment+'/iadhore_family.tsv'\n",
    "        subprocess.call([program, command, subcommand, '--input', infile, '--output', outfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_species = ['Caenorhabditis', 'Drosophila', 'Trichinella']\n",
    "all_alignment = ['BLAST', 'DIAMOND']\n",
    "for species in all_species:\n",
    "    for alignment in all_alignment:\n",
    "        the_folder = '/media/ihsan/DATA/THESIS/RUN/PREP/'+species+'/iadhore/config/'+alignment\n",
    "        os.makedirs(the_folder)\n",
    "        print(the_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_int(int_string):\n",
    "    \"\"\"\n",
    "    Check if the string can be converted to int. Return int if TRUE\n",
    "    :param int_string: String\n",
    "    :return: Integer or String\n",
    "    \"\"\"\n",
    "    try:\n",
    "        int_string = int(int_string)\n",
    "    except ValueError:\n",
    "        return int_string\n",
    "    return int_string\n",
    "\n",
    "check_int = ['12', '12.2', 'test', '+', '-']\n",
    "for c in check_int:\n",
    "    print(type(is_int(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = set([1, 2, 3])\n",
    "s2 = set([1, 2, 3])\n",
    "sfin = s1 & s2\n",
    "print(sfin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# smaller problem of alignment\n",
    "distance_dictionary = {\"dmel\": [25, 55, 75, 76, 100, 120],\n",
    "                      \"dsim\": [24, 54, 76, 77, 101, 200, 210, 215, 220],\n",
    "                      \"dyak\": [1, 57, 56, 74, 99, 170, 189, 195]}\n",
    "\n",
    "minimum_key = None\n",
    "minimum_elem = None\n",
    "\n",
    "for k, v in distance_dictionary.items():\n",
    "    \n",
    "    this_len = len(v)\n",
    "    \n",
    "    if not minimum_elem:\n",
    "        minimum_elem = this_len\n",
    "        minimum_key = k\n",
    "        continue\n",
    "    \n",
    "    if this_len < minimum_elem:\n",
    "        minimum_key = k\n",
    "        \n",
    "other_keys = set(distance_dictionary.keys())\n",
    "other_keys.discard(minimum_key)\n",
    "\n",
    "window = 2\n",
    "\n",
    "all_pairs = []\n",
    "for dist in distance_dictionary[minimum_key]:\n",
    "    pairs = None\n",
    "    for key in other_keys:\n",
    "        selected_pair = None\n",
    "        min_diff = None\n",
    "        for d in distance_dictionary[key]:\n",
    "            diff = abs(dist-d)\n",
    "            if diff <= window:\n",
    "                if not min_diff:\n",
    "                    selected_pair = d\n",
    "                    min_diff = diff\n",
    "                    continue\n",
    "                if diff < min_diff:\n",
    "                    selected_pair = d\n",
    "                    min_diff = diff\n",
    "        \n",
    "        if not selected_pair:\n",
    "            break\n",
    "            \n",
    "        if not pairs:\n",
    "            pairs = []\n",
    "        \n",
    "        pairs.append(selected_pair)\n",
    "    \n",
    "    if not pairs:\n",
    "        continue\n",
    "    \n",
    "    pairs.append(dist)\n",
    "    if len(pairs)==len(distance_dictionary):\n",
    "        all_pairs.append(pairs)\n",
    "print(all_pairs)       \n",
    "\n",
    "new_all_pairs = []\n",
    "prev_el = None\n",
    "prev_std = None\n",
    "\n",
    "for el in all_pairs:\n",
    "    \n",
    "    this_std = numpy.std(el)\n",
    "    \n",
    "    if not prev_el:\n",
    "        prev_el = el\n",
    "        prev_std = this_std\n",
    "        new_all_pairs.append(el)\n",
    "        continue\n",
    "    \n",
    "    check_prev = True\n",
    "    for e in el:\n",
    "        if e in prev_el:\n",
    "            if this_std < prev_std:\n",
    "                new_all_pairs.remove(prev_el)\n",
    "                break\n",
    "            \n",
    "            check_prev = False\n",
    "            break\n",
    "    \n",
    "    if check_prev:\n",
    "        prev_el = el\n",
    "        prev_std = this_std\n",
    "        new_all_pairs.append(el)\n",
    "                \n",
    "print(new_all_pairs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.std([76, 74, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/media/ihsan/DATA/THESIS/RUN/CORE/STORM/Drosophila/17/holohan_exp/Drosophila_melanogaster.storm', 'r') as handle:\n",
    "    record = motifs.parse(handle, 'TRANSFAC')\n",
    "    for r in record:\n",
    "        print (r.counts)\n",
    "        for k, v in r.items():\n",
    "            print (k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iadhore_dict = pi.iadhore_result_folder_to_dict(\"/media/ihsan/DATA/THESIS/MISC/TEMP/ADHORE/Drosophila/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iadhore_dict = pi.get_complete_synteny_dict(iadhore_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iadhore_dict_with_locations = cm.add_location_to_iadhore_synteny(iadhore_dict, \"/media/ihsan/DATA/THESIS/MATERIAL/Drosophila/GTF/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prep.iadhore as pi\n",
    "import core.mosyn as cm\n",
    "import prep.gtf as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('iadhore_plus_location.yaml', 'r') as stream:\n",
    "    iadhore_dict_with_locations = yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iadhore_dict_with_motifs = cm.add_motifs_into_synteny(iadhore_dict_with_locations, \"/media/ihsan/DATA/THESIS/RUN/PREP/Drosophila/storm/17/holohan_exp/GTF/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('iadhore_plus_motifs.yaml', 'w') as stream:\n",
    "    yaml.dump(iadhore_dict_with_motifs, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restructured_iadhore = cm.restructure_iadhore_dict_to_position(iadhore_dict_with_motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('iadhore_plus_motifs_restr.yaml', 'w') as stream:\n",
    "    yaml.dump(restructured_iadhore, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# smaller problem of alignment\n",
    "distance_dictionary = {\"dmel\": [25, 55, 75, 78, 100, 120, 248],\n",
    "                      \"dsim\": [24, 54, 76, 77, 101, 200, 210, 215, 220, 250],\n",
    "                      \"dyak\": [1, 57, 56, 74, 99, 170, 189, 195, 252]}\n",
    "\n",
    "window = 2\n",
    "\n",
    "all_pairs = []\n",
    "for k in distance_dictionary.keys():\n",
    "    \n",
    "    other_keys = set(distance_dictionary.keys())\n",
    "    other_keys.discard(k)\n",
    "    \n",
    "    for dist in distance_dictionary[k]:\n",
    "        \n",
    "        pairs = set()\n",
    "        \n",
    "        for key in other_keys:\n",
    "            selected_pair = None\n",
    "            min_diff = None\n",
    "            for d in distance_dictionary[key]:\n",
    "                diff = abs(dist-d)\n",
    "                if diff <= window:\n",
    "                    if min_diff == None:\n",
    "                        selected_pair = d\n",
    "                        min_diff = diff\n",
    "                        continue\n",
    "                    if diff < min_diff:\n",
    "                        selected_pair = d\n",
    "                        min_diff = diff\n",
    "\n",
    "            if not selected_pair:\n",
    "                continue\n",
    "\n",
    "            pairs.add(selected_pair)\n",
    "        \n",
    "        pairs.add(dist)\n",
    "        \n",
    "        if len(pairs)>1:\n",
    "            if pairs not in all_pairs:\n",
    "                all_pairs.append(pairs)\n",
    "\n",
    "print(all_pairs)\n",
    "\n",
    "new_all_pairs = []\n",
    "\n",
    "for el in all_pairs:\n",
    "    \n",
    "    if not new_all_pairs:\n",
    "        new_all_pairs.append(el)\n",
    "        continue\n",
    "    \n",
    "    check_prev = True\n",
    "    for e in el:\n",
    "        for ef in new_all_pairs:\n",
    "            if e in ef:\n",
    "                \n",
    "                if len(el) > len(ef):\n",
    "                    new_all_pairs.remove(ef)\n",
    "                    continue\n",
    "                \n",
    "                if len(el) < len(ef):\n",
    "                    check_prev = False\n",
    "                    break\n",
    "                    \n",
    "                this_std = np.std(list(el))\n",
    "                that_std = np.std(list(ef))\n",
    "                \n",
    "                if this_std < that_std:\n",
    "                    new_all_pairs.remove(ef)\n",
    "                    continue\n",
    "                    \n",
    "                check_prev = False\n",
    "                break\n",
    "                \n",
    "        if not check_prev:\n",
    "            break\n",
    "    \n",
    "    if check_prev:\n",
    "        new_all_pairs.append(el)\n",
    "                \n",
    "print(new_all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "single = []\n",
    "for value in distance_dictionary.values():\n",
    "    for val in value:\n",
    "        check_single = True\n",
    "        for pair in new_all_pairs:  \n",
    "            if val in pair:\n",
    "                check_single = False\n",
    "                break\n",
    "        if check_single:\n",
    "            single.append(val)\n",
    "print(single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# smaller problem of alignment\n",
    "distance_dictionary = {\"dmel\": [25, 28, 75, 78, 100, 104, 248],\n",
    "                      \"dsim\": [29, 26, 76, 79, 101, 105, 210, 215, 220, 250],\n",
    "                      \"dyak\": [27, 30, 77, 80, 102, 106, 225, 245, 252]}\n",
    "\n",
    "window = 10\n",
    "\n",
    "everything_pairs = []\n",
    "for k in distance_dictionary.keys():\n",
    "    \n",
    "    other_keys = set(distance_dictionary.keys())\n",
    "    other_keys.discard(k)\n",
    "    \n",
    "    \n",
    "    for dist in distance_dictionary[k]:\n",
    "        all_pairs = []\n",
    "        for key in other_keys:\n",
    "            selected_pairs = []\n",
    "            for d in distance_dictionary[key]:\n",
    "                diff = abs(dist-d)\n",
    "                if diff <= window:\n",
    "                    selected_pairs.append(d)\n",
    "                    continue\n",
    "                    \n",
    "            if not selected_pairs:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            if not all_pairs:\n",
    "                for sl in selected_pairs:\n",
    "                    all_pairs.append([sl])\n",
    "                continue\n",
    "            \n",
    "            mod_all_pairs = []    \n",
    "            for pairs in all_pairs:\n",
    "                for sl in selected_pairs:\n",
    "                    mod_all_pairs.append(pairs + [sl])\n",
    "            all_pairs = mod_all_pairs\n",
    "        \n",
    "        if not all_pairs:\n",
    "            continue\n",
    "            \n",
    "        for pairs in all_pairs:\n",
    "            everything_pairs.append(pairs + [dist])\n",
    "\n",
    "print (everything_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_pairs = []\n",
    "\n",
    "for el in everything_pairs:\n",
    "    \n",
    "    if not new_all_pairs:\n",
    "        new_all_pairs.append(el)\n",
    "        continue\n",
    "    \n",
    "    check_prev = True\n",
    "    for e in el:\n",
    "        for ef in new_all_pairs:\n",
    "            if e in ef:\n",
    "                \n",
    "                if len(el) > len(ef):\n",
    "                    new_all_pairs.remove(ef)\n",
    "                    continue\n",
    "                \n",
    "                if len(el) < len(ef):\n",
    "                    check_prev = False\n",
    "                    break\n",
    "                    \n",
    "                this_std = sum(list(el))\n",
    "                that_std = sum(list(ef))\n",
    "                \n",
    "                if this_std < that_std:\n",
    "                    new_all_pairs.remove(ef)\n",
    "                    continue\n",
    "                    \n",
    "                check_prev = False\n",
    "                break\n",
    "                \n",
    "        if not check_prev:\n",
    "            break\n",
    "    \n",
    "    if check_prev:\n",
    "        new_all_pairs.append(el)\n",
    "        \n",
    "for el in everything_pairs:\n",
    "    \n",
    "    check_prev = True\n",
    "    for e in el:\n",
    "        for ef in new_all_pairs:\n",
    "            if e in ef:\n",
    "                check_prev = False\n",
    "                break\n",
    "                \n",
    "        if not check_prev:\n",
    "            break\n",
    "    \n",
    "    if check_prev:\n",
    "        new_all_pairs.append(el)\n",
    "                \n",
    "print(new_all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[[26, 27, 25], [29, 30, 28], [76, 77, 75], [79, 80, 78], [101, 102, 100], [105, 106, 104], [250, 252, 248], [225, 220]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_pairs = []\n",
    "\n",
    "for el in everything_pairs:\n",
    "    \n",
    "    check_prev = True\n",
    "    for e in el:\n",
    "        for ef in new_all_pairs:\n",
    "\n",
    "            if e in ef:\n",
    "                \n",
    "                if len(el) > len(ef):\n",
    "                    continue\n",
    "                \n",
    "                if len(el) < len(ef):\n",
    "                    check_prev = False\n",
    "                    break\n",
    "                    \n",
    "                this_std = np.std(list(el))\n",
    "                that_std = np.std(list(ef))\n",
    "                \n",
    "                if this_std < that_std:\n",
    "                    continue\n",
    "                    \n",
    "                check_prev = False\n",
    "                break\n",
    "                \n",
    "        if not check_prev:\n",
    "            break\n",
    "    \n",
    "    if check_prev:\n",
    "        new_all_pairs.append(el)\n",
    "                \n",
    "print(new_all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for pair in new_all_pairs:\n",
    "    counter += len(pair)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import core.mosyn as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('iadhore_plus_motifs_restr.yaml', 'r') as stream:\n",
    "    restructured_iadhore = yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iadhore_with_motifs_pair = cm.align_motifs_in_synteny(restructured_iadhore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('iadhore_plus_motifs_pair.yaml', 'w') as stream:\n",
    "    yaml.dump(iadhore_with_motifs_pair, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count0 = 0\n",
    "count1 = 0\n",
    "\n",
    "for key, value in iadhore_with_motifs_pair.items():\n",
    "    for ke, val in value.items():\n",
    "        for k in val.keys():\n",
    "            \n",
    "            if k == \"motifs\":\n",
    "                for pair in val[k]:\n",
    "                    for p in pair:\n",
    "                        count1 += 1\n",
    "                continue\n",
    "            \n",
    "            if \"motifs\" not in val[k].keys():\n",
    "                continue\n",
    "\n",
    "            for motif in val[k][\"motifs\"]:\n",
    "                count0 += 1\n",
    "                \n",
    "print(count0, count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import core.mosyn as cm\n",
    "import prep.iadhore as pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iadhore_dict = pi.iadhore_result_folder_to_dict(\"/media/ihsan/DATA/THESIS/MISC/TEMP/ADHORE/Drosophila/\")\n",
    "iadhore_dict = pi.get_complete_synteny_dict(iadhore_dict)\n",
    "iadhore_dict_with_locations = cm.add_location_to_iadhore_synteny(iadhore_dict, \"/media/ihsan/DATA/THESIS/MATERIAL/Drosophila/GTF/\")\n",
    "iadhore_dict_with_motifs = cm.add_motifs_into_synteny(iadhore_dict_with_locations, \"/media/ihsan/DATA/THESIS/RUN/PREP/Drosophila/storm/17/holohan_exp/GTF/\")\n",
    "restructured_iadhore = cm.restructure_iadhore_dict_to_position(iadhore_dict_with_motifs)\n",
    "iadhore_with_motifs_pair = cm.align_motifs_in_synteny(restructured_iadhore)\n",
    "synteny_motifs_complete = cm.get_complete_motifs_synteny(iadhore_with_motifs_pair)\n",
    "\n",
    "cm.dump_aligned_motifs_to_flat_synteny(synteny_motifs_complete, \"flat_synteny_motifs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count0 = 0\n",
    "count1 = 0\n",
    "\n",
    "for key, value in iadhore_with_motifs_pair.items():\n",
    "    for ke, val in value.items():\n",
    "        for k in val.keys():\n",
    "            \n",
    "            if k == \"motifs\":\n",
    "                for pair in val[k]:\n",
    "                    for p in pair:\n",
    "                        count1 += 1\n",
    "                continue\n",
    "            \n",
    "for key, value in iadhore_dict_with_motifs.items():\n",
    "    for k, v in value[\"segments\"].items():\n",
    "        for k0, v0 in v[\"elements\"].items():\n",
    "            if \"motifs\" not in v0.keys():\n",
    "                continue\n",
    "            count0 += len(v0[\"motifs\"])\n",
    "                \n",
    "print(count0, count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('synteny_motifs.yaml', 'w') as stream:\n",
    "    yaml.dump(iadhore_with_motifs_pair, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('synteny_motifs_and_loops_1.yaml', 'w') as stream:\n",
    "    yaml.dump(mosyn_dict, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for all condition\n",
    "\n",
    "fout = open(\"loops.csv\", 'w')\n",
    "loops_dictionary = dict()\n",
    "start_id = 1\n",
    "for key, value in sorted(mosyn_dict.items()):\n",
    "    \n",
    "    if \"loops\" not in value.keys():\n",
    "        continue\n",
    "    \n",
    "    this_loops = dict()\n",
    "    for loop in value[\"loops\"]:\n",
    "        \n",
    "        this_key = (loop[\"genome\"], loop[\"chromosome\"], loop[\"start\"])\n",
    "        this_loops[this_key] = loop\n",
    "        \n",
    "    for ke, val in sorted(this_loops.items()):\n",
    "        loops_dictionary[start_id] = val\n",
    "        loops_dictionary[start_id][\"multiplicon\"] = key\n",
    "        start_id += 1\n",
    "\n",
    "print(\"loop_id\", \"synteny_id\", \"genome\", \"chromosome\", \"first\", \"last\", \"start\", \"end\", sep=\",\", file=fout)\n",
    "selected_keys = [\"multiplicon\", \"genome\", \"chromosome\", \"first\", \"last\", \"start\", \"end\"]\n",
    "for key, value in sorted(loops_dictionary.items()):\n",
    "    \n",
    "    print_values = [str(value[sk]) for sk in selected_keys]\n",
    "    print_values = \",\".join(print_values)\n",
    "    print(key, print_values, sep=\",\", file=fout)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are identifying the loops\n",
    "with open('/media/ihsan/DATA/THESIS/RESULT/Primary/Trichinella/DIAMOND/holohan_exp/synteny.yaml', 'r') as stream:\n",
    "    mosyn_dict = yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(mosyn_dict.items()):\n",
    "    \n",
    "    # first check the occurence of \"motifs\" key\n",
    "    key_counter = 0\n",
    "    for ke, val in sorted(value.items()):\n",
    "        \n",
    "        if \"motifs\" in val.keys():\n",
    "            key_counter += 1\n",
    "    \n",
    "    if key_counter < 2:\n",
    "        continue\n",
    "        \n",
    "    # then get list of segment\n",
    "    set_of_segments = set()\n",
    "    for ke, val in sorted(value.items()):\n",
    "        for k in val.keys():\n",
    "            if k == \"motifs\":\n",
    "                continue\n",
    "            v = val[k]\n",
    "            set_of_segments.add((v[\"genome\"], v[\"chromosome\"]))\n",
    "    \n",
    "    loops = []\n",
    "    for seg in sorted(set_of_segments):\n",
    "        \n",
    "        current_strand = None\n",
    "        current_motif = None\n",
    "        current_pair = None\n",
    "        current_size = 0\n",
    "        \n",
    "        inverse_strand = None\n",
    "        inverse_motif = None\n",
    "        inverse_pair = None\n",
    "        inverse_size = 0\n",
    "        \n",
    "        for ke, val in sorted(value.items()):\n",
    "            if \"motifs\" in val.keys():\n",
    "                for pair in val[\"motifs\"]:\n",
    "                    for m in pair:\n",
    "                        m_genome = m[\"genome\"]\n",
    "                        m_chromosome = m[\"chromosome\"]\n",
    "                        m_gc = (m_genome, m_chromosome)\n",
    "                    \n",
    "                        if not (m_gc == seg):\n",
    "                            continue\n",
    "                        \n",
    "                        if not current_motif:\n",
    "                            current_strand = m[\"strand\"]\n",
    "                            current_motif = m\n",
    "                            continue\n",
    "                            \n",
    "                        loc = [current_motif[\"start\"], current_motif[\"end\"], m[\"start\"], m[\"end\"]]\n",
    "                        start = min(loc)\n",
    "                        end = max(loc)\n",
    "                        size = end - start\n",
    "                            \n",
    "                        if current_strand != m[\"strand\"]:\n",
    "                            \n",
    "                            if not inverse_motif:\n",
    "                                inverse_strand = m[\"strand\"]\n",
    "                                inverse_motif = m\n",
    "                            \n",
    "                            if (not current_pair) or (size > current_size):\n",
    "                                current_pair = m\n",
    "                                current_size = size\n",
    "                                continue\n",
    "                                \n",
    "                        else:\n",
    "                            \n",
    "                            if (not inverse_pair) or (size > inverse_size):\n",
    "                                inverse_pair = m\n",
    "                                inverse_size = size\n",
    "                                continue\n",
    "        \n",
    "        current_loop = None\n",
    "        if current_motif and current_pair:\n",
    "            current_loc = [current_motif[\"start\"], current_motif[\"end\"], current_pair[\"start\"], current_pair[\"end\"]]\n",
    "            current_motif_id = sorted([current_motif[\"motif\"], current_pair[\"motif\"]])\n",
    "            current_start = min(current_loc)\n",
    "            current_end = max(current_loc)\n",
    "            current_loop = {\"start\": current_start, \"end\": current_end, \n",
    "                    \"chromosome\": current_motif[\"chromosome\"], \"genome\": current_motif[\"genome\"], \n",
    "                   \"first\": current_motif_id[0], \"last\": current_motif_id[1]}\n",
    "            \n",
    "        inverse_loop = None                      \n",
    "        if inverse_motif and inverse_pair:\n",
    "            inverse_loc = [inverse_motif[\"start\"], inverse_motif[\"end\"], inverse_pair[\"start\"], inverse_pair[\"end\"]]\n",
    "            inverse_motif_id = sorted([inverse_motif[\"motif\"], inverse_pair[\"motif\"]])\n",
    "            inverse_start = min(inverse_loc)\n",
    "            inverse_end = max(inverse_loc)\n",
    "            inverse_loop = {\"start\": inverse_start, \"end\": inverse_end, \n",
    "                    \"chromosome\": inverse_motif[\"chromosome\"], \"genome\": inverse_motif[\"genome\"],\n",
    "                   \"first\": inverse_motif_id[0], \"last\": inverse_motif_id[1]}\n",
    "            \n",
    "        if current_loop:\n",
    "            loops.append(current_loop)\n",
    "            if inverse_loop:\n",
    "                if current_start <= inverse_start and current_end >= inverse_end:\n",
    "                    continue\n",
    "                loops.append(inverse_loop)\n",
    "                \n",
    "    if loops:\n",
    "        mosyn_dict[key][\"loops\"] = loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for complete synteny only\n",
    "\n",
    "fout = open(\"trichinella_loops_complete.csv\", 'w')\n",
    "loops_dictionary = dict()\n",
    "start_id = 1\n",
    "for key, value in sorted(mosyn_dict.items()):\n",
    "    \n",
    "    if \"loops\" not in value.keys():\n",
    "        continue\n",
    "    \n",
    "    genome_chromosome_set = set()\n",
    "    for loop in value[\"loops\"]:\n",
    "        \n",
    "        genome_chromosome_set.add((loop[\"genome\"], loop[\"chromosome\"]))\n",
    "        \n",
    "    num_of_element = len(value[\"loops\"]) / len(genome_chromosome_set)\n",
    "    num_of_element = int(num_of_element)\n",
    "    \n",
    "    pair_loops = dict()\n",
    "    for i in range(num_of_element):\n",
    "        pair_loops[start_id] = []\n",
    "        for j in range(i, len(value[\"loops\"]), num_of_element):\n",
    "            pair_loops[start_id].append(value[\"loops\"][j])\n",
    "        start_id += 1\n",
    "            \n",
    "    loops_dictionary[key] = pair_loops\n",
    "\n",
    "selected_keys = [\"genome\", \"chromosome\", \"first\", \"last\", \"start\", \"end\"]\n",
    "for key, value in sorted(loops_dictionary.items()):\n",
    "    \n",
    "    for ke, val in sorted(value.items()):\n",
    "        print_values = []\n",
    "        for v in val:\n",
    "            for sk in selected_keys:\n",
    "                print_values.append(str(v[sk]))\n",
    "                \n",
    "        print_str = \",\".join(print_values)\n",
    "        print(ke, key, print_str, sep=\",\", file=fout)\n",
    "        \n",
    "fout.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
